generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Account {
  id                String  @id @default(cuid())
  userId            String
  type              String
  provider          String
  providerAccountId String
  refresh_token     String? // @db.Text
  access_token      String? // @db.Text
  expires_in        Int?
  expires_at        Int?
  token_type        String?
  scope             String?
  id_token          String? // @db.Text
  session_state     String?
  user              User    @relation(fields: [userId], references: [id], onDelete: Cascade)

  @@unique([provider, providerAccountId])
}

model Session {
  id           String   @id @default(cuid())
  sessionToken String   @unique
  userId       String
  expires      DateTime
  user         User     @relation(fields: [userId], references: [id], onDelete: Cascade)
}

model User {
  id            String    @id @default(cuid())
  name          String?
  email         String?   @unique
  emailVerified DateTime?
  image         String?
  accounts      Account[]
  sessions      Session[]
  // Password hash for Credentials provider auth (nullable to allow future OAuth)
  passwordHash  String?
}

model VerificationToken {
  identifier String
  token      String   @unique
  expires    DateTime

  @@unique([identifier, token])
}

/// --- AI Prompting & Evals ---

enum RunStatus {
  SUCCESS
  ERROR
  PARTIAL
}

/// Single prompt per task (e.g., "chapter_summary") with default model/params
model Prompt {
  id              String          @id @default(cuid())
  task            String          @unique
  description     String?
  defaultModel    String          @default("gpt-4o-mini")
  defaultTemp     Float           @default(0.2)
  defaultTopP     Float?
  activeVersionId String?         @unique
  activeVersion   PromptVersion?  @relation("ActivePromptVersion", fields: [activeVersionId], references: [id])
  versions        PromptVersion[]
  createdAt       DateTime        @default(now())
  updatedAt       DateTime        @updatedAt
}

/// Immutable template version; may override model params for rare A/B
model PromptVersion {
  id            String   @id @default(cuid())
  promptId      String
  template      String
  system        String?
  modelOverride String?
  tempOverride  Float?
  topPOverride  Float?
  metadata      Json?
  createdById   String?
  createdAt     DateTime @default(now())

  PromptRun PromptRun[]
  Prompt    Prompt?     @relation(fields: [promptId], references: [id])
  activeFor Prompt?     @relation("ActivePromptVersion")

  @@index([promptId, createdAt])
}

/// Run log for prompt generations
model PromptRun {
  id              String          @id @default(cuid())
  promptVersionId String
  promptVersion   PromptVersion   @relation(fields: [promptVersionId], references: [id], onDelete: Cascade)
  model           String
  inputVars       Json
  compiledPrompt  String
  systemUsed      String?
  outputHtml      String?
  rawResponse     Json?
  usage           Json?
  status          RunStatus       @default(SUCCESS)
  error           String?
  qaTranscript    Json?
  createdAt       DateTime        @default(now())
  userId          String?
  HumanFeedback   HumanFeedback[]

  @@index([promptVersionId, createdAt])
}

model HumanFeedback {
  id          String    @id @default(cuid())
  promptRunId String
  promptRun   PromptRun @relation(fields: [promptRunId], references: [id], onDelete: Cascade)
  rating      Int?
  comment     String?
  createdById String?
  createdAt   DateTime  @default(now())
}

/// Centralized log of all LLM requests, regardless of feature
model LlmRequest {
  id               String    @id @default(cuid())
  createdAt        DateTime  @default(now())
  // Inputs
  model            String
  system           String?
  userPrompt       String // @db.Text
  temperature      Float?
  topP             Float?
  // Outputs
  status           RunStatus @default(PARTIAL)
  outputText       String?
  rawResponse      Json?
  usage            Json?
  // Token info (normalized across providers)
  promptTokens     Int?
  completionTokens Int?
  totalTokens      Int?
  // Error message if any
  error            String?

  @@index([createdAt])
}

/// Minimal document for Markdown ingest
model Doc {
  id                String   @id @default(cuid())
  title             String
  markdown          String // @db.Text
  html              String // @db.Text
  // Source + content id form a stable identity for ingest pipelines
  originalSource    String?
  originalContentId String?
  contentHash       String?
  // Dot path for filtering/nesting (e.g., "work.projects.alpha")
  path              String?
  // Arbitrary single-level key/value pairs from client (stored as JSONB)
  meta              Json?
  createdAt         DateTime @default(now())
  updatedAt         DateTime @updatedAt

  // Relations
  docEmbeddings        DocEmbedding[]
  umapPoints           UmapPoint[]
  sections             DocSection[]
  docSectionEmbeddings DocSectionEmbedding[]

  @@unique([originalSource, originalContentId])
  @@index([path])
}

/// Structural sections/chunks of a Doc after preprocessing
model DocSection {
  id          String   @id @default(cuid())
  docId       String
  headingPath String[] @default([])
  text        String // @db.Text
  contentHash String
  orderIndex  Int
  charCount   Int
  tokenCount  Int?

  doc        Doc                   @relation(fields: [docId], references: [id], onDelete: Cascade)
  embeddings DocSectionEmbedding[]

  @@unique([docId, contentHash])
  @@index([docId, orderIndex])
}

/// Vector embedding run metadata
model EmbeddingRun {
  id        String   @id @default(cuid())
  model     String
  dims      Int
  params    Json?
  createdAt DateTime @default(now())

  docEmbeddings        DocEmbedding[]
  docSectionEmbeddings DocSectionEmbedding[]
  UmapRun              UmapRun[]
}

/// Embedding vector for a full Doc under a specific EmbeddingRun
model DocEmbedding {
  id           String   @id @default(cuid())
  runId        String
  docId        String
  vector       Float[]
  contentHash  String?
  sectionCount Int?
  tokenCount   Int?
  createdAt    DateTime @default(now())

  run EmbeddingRun @relation(fields: [runId], references: [id], onDelete: Cascade)
  doc Doc          @relation(fields: [docId], references: [id], onDelete: Cascade)

  @@unique([runId, docId])
  @@index([docId])
  @@index([contentHash])
}

/// Embedding vector for a specific DocSection under a given EmbeddingRun
model DocSectionEmbedding {
  id         String   @id @default(cuid())
  runId      String
  docId      String
  sectionId  String
  vector     Float[]
  tokenCount Int?
  createdAt  DateTime @default(now())

  run     EmbeddingRun @relation(fields: [runId], references: [id], onDelete: Cascade)
  doc     Doc          @relation(fields: [docId], references: [id], onDelete: Cascade)
  section DocSection   @relation(fields: [sectionId], references: [id], onDelete: Cascade)

  @@unique([runId, sectionId])
  @@index([docId])
}

/// UMAP projection run over a given EmbeddingRun
model UmapRun {
  id             String   @id @default(cuid())
  embeddingRunId String
  dims           Int
  params         Json?
  createdAt      DateTime @default(now())

  embeddingRun EmbeddingRun @relation(fields: [embeddingRunId], references: [id], onDelete: Cascade)
  points       UmapPoint[]

  @@index([embeddingRunId, createdAt])
}

/// Coordinates for each Doc in a UMAP projection run
model UmapPoint {
  id    String @id @default(cuid())
  runId String
  docId String
  x     Float
  y     Float
  z     Float?

  run UmapRun @relation(fields: [runId], references: [id], onDelete: Cascade)
  doc Doc     @relation(fields: [docId], references: [id], onDelete: Cascade)

  @@unique([runId, docId])
  @@index([docId])
}
